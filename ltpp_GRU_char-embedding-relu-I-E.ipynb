{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>mbti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352956832</td>\n",
       "      <td>it</td>\n",
       "      <td>['Feeling cranky and very little inclined to s...</td>\n",
       "      <td>ISTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301484731</td>\n",
       "      <td>it</td>\n",
       "      <td>['@Sgrattia o dormire morendo', 'i dipendenti ...</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>163103634</td>\n",
       "      <td>it</td>\n",
       "      <td>['Facebook full of viruses, hackers and bullsh...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629069123</td>\n",
       "      <td>it</td>\n",
       "      <td>['@F_Molinari complimenti,il mio gatto patta m...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>875579587</td>\n",
       "      <td>it</td>\n",
       "      <td>['E infine: https://t.co/3Lpt72bnet', \"Sbaglio...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id lang                                               text  mbti\n",
       "1  352956832   it  ['Feeling cranky and very little inclined to s...  ISTP\n",
       "2  301484731   it  ['@Sgrattia o dormire morendo', 'i dipendenti ...  INTP\n",
       "3  163103634   it  ['Facebook full of viruses, hackers and bullsh...  INTJ\n",
       "4  629069123   it  ['@F_Molinari complimenti,il mio gatto patta m...  INFP\n",
       "5  875579587   it  ['E infine: https://t.co/3Lpt72bnet', \"Sbaglio...  INTJ"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv('twistytest.csv', \n",
    "                     index_col=0, \n",
    "                     header=1, \n",
    "                     names=['user_id', 'lang', 'text', 'mbti'])\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id lang                                               text mbti\n",
      "1  352956832   it  ['Feeling cranky and very little inclined to s...    I\n",
      "2  301484731   it  ['@Sgrattia o dormire morendo', 'i dipendenti ...    I\n",
      "3  163103634   it  ['Facebook full of viruses, hackers and bullsh...    I\n",
      "4  629069123   it  ['@F_Molinari complimenti,il mio gatto patta m...    I\n",
      "5  875579587   it  ['E infine: https://t.co/3Lpt72bnet', \"Sbaglio...    I\n"
     ]
    }
   ],
   "source": [
    "#for name1, g1 in corpus.groupby('mbti'):\n",
    "#    for name2, g2 in g1.groupby('lang'):\n",
    "#        print(name1, name2, g1.shape, g2.shape)\n",
    "mask = corpus['mbti'].isin(['ESFP', 'ESTP', 'ESFJ', 'ESTJ'])\n",
    "corpus['mbti'] = corpus.mbti.apply(lambda x: x[0]) # trim annotation to I-E\n",
    "print(corpus.head())\n",
    "filtered = corpus[~mask].sample(frac=0.1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(filtered.text.tolist(), \n",
    "                                                    filtered.mbti.tolist(), \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "y2i = defaultdict(lambda: len(y2i))\n",
    "y_train_num = [y2i[mbti] for mbti in y_train]\n",
    "y_test_num = [y2i[mbti] for mbti in y_test]\n",
    "num_classes = len(np.unique(y_train_num))\n",
    "y_train_one_hot = np_utils.to_categorical(y_train_num, num_classes) #important to give the num_classes!\n",
    "y_test_one_hot = np_utils.to_categorical(y_test_num, num_classes) #important to give the num_classes!\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44158\n"
     ]
    }
   ],
   "source": [
    "c2i = defaultdict(lambda: len(c2i))\n",
    "PAD = c2i[\"<\"] # index 0 is padding\n",
    "UNK = c2i[\"+\"] # index 1 is for UNK\n",
    "\n",
    "# convert words to indices, taking care of UNKs\n",
    "X_train_num = [[c2i[char] for char in sentence] for sentence in X_train]\n",
    "c2i = defaultdict(lambda: UNK, c2i) # freeze - cute trick!\n",
    "X_test_num = [[c2i[char] for char in sentence] for sentence in X_test]\n",
    "\n",
    "max_sentence_length=max([len(s.split(\" \")) for s in X_train] \n",
    "                        + [len(s.split(\" \")) for s in X_test] )\n",
    "print(max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 44158)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "# pad X\n",
    "X_train_pad = sequence.pad_sequences(X_train_num, maxlen=max_sentence_length, value=PAD)\n",
    "X_test_pad = sequence.pad_sequences(X_test_num, maxlen=max_sentence_length,value=PAD)\n",
    "print(X_train_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(c2i)\n",
    "embeds_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(113) #set seed before any keras import\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embeds_size, input_length=max_sentence_length))\n",
    "model.add(GRU(32, return_sequences=True))\n",
    "model.add(GRU(32, go_backwards=True))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('relu'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "68/68 [==============================] - 771s - loss: nan - acc: 0.8529    \n",
      "Epoch 2/3\n",
      "68/68 [==============================] - 717s - loss: nan - acc: 0.8529    \n",
      "Epoch 3/3\n",
      "68/68 [==============================] - 619s - loss: nan - acc: 0.8529    \n",
      "18/18 [==============================] - 4s\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train_one_hot, epochs=3, batch_size=2)\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  88.8888895512\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"337pt\" viewBox=\"0.00 0.00 255.00 337.00\" width=\"255pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 333)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-333 251,-333 251,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 139786177294064 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>139786177294064</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 247,-328.5 247,-292.5 0,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.5\" y=\"-306.8\">embedding_3_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139786177294008 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>139786177294008</title>\n",
       "<polygon fill=\"none\" points=\"22,-219.5 22,-255.5 225,-255.5 225,-219.5 22,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.5\" y=\"-233.8\">embedding_3: Embedding</text>\n",
       "</g>\n",
       "<!-- 139786177294064&#45;&gt;139786177294008 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>139786177294064-&gt;139786177294008</title>\n",
       "<path d=\"M123.5,-292.4551C123.5,-284.3828 123.5,-274.6764 123.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"127.0001,-265.5903 123.5,-255.5904 120.0001,-265.5904 127.0001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139786177293896 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>139786177293896</title>\n",
       "<polygon fill=\"none\" points=\"73,-146.5 73,-182.5 174,-182.5 174,-146.5 73,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.5\" y=\"-160.8\">gru_1: GRU</text>\n",
       "</g>\n",
       "<!-- 139786177294008&#45;&gt;139786177293896 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>139786177294008-&gt;139786177293896</title>\n",
       "<path d=\"M123.5,-219.4551C123.5,-211.3828 123.5,-201.6764 123.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"127.0001,-192.5903 123.5,-182.5904 120.0001,-192.5904 127.0001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139786191049728 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>139786191049728</title>\n",
       "<polygon fill=\"none\" points=\"59.5,-73.5 59.5,-109.5 187.5,-109.5 187.5,-73.5 59.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.5\" y=\"-87.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 139786177293896&#45;&gt;139786191049728 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>139786177293896-&gt;139786191049728</title>\n",
       "<path d=\"M123.5,-146.4551C123.5,-138.3828 123.5,-128.6764 123.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"127.0001,-119.5903 123.5,-109.5904 120.0001,-119.5904 127.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139786177305232 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>139786177305232</title>\n",
       "<polygon fill=\"none\" points=\"30,-.5 30,-36.5 217,-36.5 217,-.5 30,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.5\" y=\"-14.8\">activation_2: Activation</text>\n",
       "</g>\n",
       "<!-- 139786191049728&#45;&gt;139786177305232 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>139786191049728-&gt;139786177305232</title>\n",
       "<path d=\"M123.5,-73.4551C123.5,-65.3828 123.5,-55.6764 123.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"127.0001,-46.5903 123.5,-36.5904 120.0001,-46.5904 127.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- run with 0.4 percent of dataset\n",
    "- with bi-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvltp",
   "language": "python",
   "name": "venvltp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
